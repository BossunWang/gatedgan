{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install visdom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "import numpy as np\n",
    "# vis = visdom.Visdom()\n",
    "# vis.text('Hello, world!')\n",
    "# vis.image(np.ones((3, 10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from data import *\n",
    "from models import *\n",
    "from utils import *\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN OPTIONS FROM GATED GAN\n",
    "epoch = 0\n",
    "n_epochs = 200 #default = 200\n",
    "batchSize = 1\n",
    "dataroot = './photo2fourcollection'\n",
    "loadSize = 143\n",
    "fineSize = 128\n",
    "ngf = 64\n",
    "ndf = 64    \n",
    "in_nc = 3 \n",
    "out_nc = 3 \n",
    "niter = 100  \n",
    "niter_decay = 100 \n",
    "lr = 0.0002 \n",
    "beta1 = 0.5 \n",
    "#ntrain = math.huge \n",
    "flip = 1  \n",
    "display_id = 10 \n",
    "display_winsize = 128 \n",
    "display_freq = 25 \n",
    "gpu = 1 \n",
    "name = ''   \n",
    "which_direction = 'AtoB'\n",
    "phase = 'train'\n",
    "nThreads = 2\n",
    "save_epoch_freq = 1\n",
    "save_latest_freq = 5000 \n",
    "print_freq = 50\n",
    "save_display_feq = 2500\n",
    "continue_train = 0\n",
    "serial_batches = 0\n",
    "checkpoints_dir = './checkpoints'\n",
    "cudnn = 1\n",
    "which_model_netD = 'basic'\n",
    "which_model_netG = 'auto_gated_resnet_6blocks'\n",
    "norm = 'instance'\n",
    "n_layers_D = 3\n",
    "lambda_A = 10.0\n",
    "lambda_B = 10.0\n",
    "model = 'gated_gan'\n",
    "use_lsgan = 1\n",
    "align_data = 0\n",
    "pool_size = 50\n",
    "resize_or_crop = 'resize_and_crop'\n",
    "autoencoder_constrain = 10 \n",
    "n_styles = 4\n",
    "test_data_path = ''\n",
    "decay_epoch=100\n",
    "cuda=False\n",
    "tv_strength=1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ImageDataset('./photo2fourcollection'), \n",
    "                        batch_size=1, shuffle=True, num_workers=4)\n",
    "batch = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['style_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(in_nc, out_nc, n_styles, ngf)\n",
    "discriminator= Discriminator(in_nc,n_styles, ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Losses Init\n",
    "use_lsgan=True\n",
    "if use_lsgan:\n",
    "    criterion_GAN = nn.MSELoss()\n",
    "else: \n",
    "    criterion_GAN = nn.BCELoss()\n",
    "    \n",
    "    \n",
    "criterion_ACGAN = nn.CrossEntropyLoss(weight=None)\n",
    "criterion_Rec = nn.L1Loss()\n",
    "criterion_Enc = nn.MSELoss()\n",
    "criterion_TV = TVLoss(TVLoss_weight=tv_strength)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers & LR schedulers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),\n",
    "                                lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), \n",
    "                               lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch,decay_epoch).step)\n",
    "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(n_epochs,epoch, decay_epoch).step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (fldiscriminator): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       "  (aux_clf): Conv2d(512, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set vars for training\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "input_A = Tensor(batchSize, in_nc, fineSize, fineSize)\n",
    "input_B = Tensor(batchSize, out_nc, fineSize, fineSize)\n",
    "target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "# print(Tensor(batch['style']))\n",
    "D_A_size = discriminator(input_A.copy_(batch['style']))[0].size()  \n",
    "D_AC_size = discriminator(input_B.copy_(batch['style']))[1].size()\n",
    "# print(D_AC_size)\n",
    "\n",
    "class_label_B = Tensor(D_AC_size[0],D_AC_size[1],D_AC_size[2]).long()\n",
    "# print(class_label_B.shape)\n",
    "\n",
    "autoflag_OHE = Tensor(1,n_styles+1).fill_(0).long()\n",
    "autoflag_OHE[0][-1] = 1\n",
    "\n",
    "fake_label = Tensor(D_A_size).fill_(0.0)\n",
    "real_label = Tensor(D_A_size).fill_(0.9) \n",
    "\n",
    "rec_A_AE = Tensor(batchSize,in_nc,fineSize,fineSize)\n",
    "\n",
    "fake_buffer = ReplayBuffer()\n",
    "\n",
    "##INIT THOSE WEIGHTS INIT\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(n_epochs, len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check out our training tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#source image\n",
    "real_content = Variable(input_A.copy_(batch['content']))\n",
    "#target style\n",
    "real_style = Variable(input_B.copy_(batch['style']))\n",
    "#simple label of style index\n",
    "style_label = batch['style_label']\n",
    "#one hot encoded style label\n",
    "style_OHE = F.one_hot(style_label,n_styles).long()\n",
    "#\n",
    "class_label = class_label_B.copy_(label2tensor(style_label,class_label_B)).long()\n",
    "\n",
    "#\n",
    "#rec_AE = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_style.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_OHE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(class_label.shape)\n",
    "class_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G.zero_grad()\n",
    "generator.zero_grad()\n",
    "discriminator.zero_grad()\n",
    "rec = generator({\n",
    "    'content':real_content,\n",
    "    'style_label': autoflag_OHE # 1-n_styles +1 ((nstyles))\n",
    "        })\n",
    "err_Rec = criterion_Rec(rec,real_content)*autoencoder_constrain\n",
    "err_Rec.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7917, grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "#Gan Loss\n",
    "genfake = generator({\n",
    "    'content':real_content,\n",
    "    'style_label': style_OHE})\n",
    "\n",
    "print(err_Rec)\n",
    "print(genfake.shape)\n",
    "\n",
    "output = discriminator(genfake)\n",
    "errG = criterion_GAN(output[0],fake_label)\n",
    "errG.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "errG_AC = criterion_ACGAN(output[1].transpose(1,3),class_label)*lambda_A\n",
    "errG_AC.backward(retain_graph=True)\n",
    "\n",
    "err_TV = criterion_TV(genfake)\n",
    "err_TV.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_G= err_Rec + errG + errG_AC + err_TV\n",
    "optimizer_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genfake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-090177ba61e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#Fake Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_and_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mout_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0merrD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_real\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genfake' is not defined"
     ]
    }
   ],
   "source": [
    "#### DISCRIMINATOR UPDATE\n",
    "optimizer_D.zero_grad()\n",
    "generator.zero_grad()\n",
    "discriminator.zero_grad()\n",
    "\n",
    "#Real Loss\n",
    "output = discriminator(real_style)\n",
    "\n",
    "errD_real_class = criterion_ACGAN(output[1].transpose(1,3),class_label)\n",
    "errD_real_class.backward(retain_graph=True)\n",
    "\n",
    "errD_real = criterion_GAN(output[0],real_label)\n",
    "errD_real.backward()\n",
    "\n",
    "#Fake Loss\n",
    "fake = fake_buffer.push_and_pop(genfake)\n",
    "out_real, out_class = discriminator(fake)\n",
    "errD_fake = criterion_GAN(out_real,fake_label)\n",
    "errD_fake.backward()\n",
    "\n",
    "errD = (errD_real+errD_fake)/2.0\n",
    "\n",
    "optimizer_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1354, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 16])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 [0012/6287] -- loss_G: 25.2268 | loss_G_AE: 5.3283 | loss_G_GAN: 1.3296 | loss_G_AC: 18.5687 | loss_D: 1.4596 | errD_fake: 1.3296 | tv_oss: 0.0002 | errD_real: 1.5895 | errD_class: 1.8281 -- ETA: 74 days, 12:40:09.2477952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-05bab53ff0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#https://github.com/pytorch/pytorch/issues/29\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TRAIN LOOP\n",
    "for epoch in range(epoch,n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_content = Variable(input_A.copy_(batch['content']))\n",
    "        real_style = Variable(input_B.copy_(batch['style']))\n",
    "        style_label = batch['style_label']\n",
    "        style_OHE = F.one_hot(style_label,n_styles).long()\n",
    "        \n",
    "        class_label = class_label_B.copy_(label2tensor(style_label,class_label_B)).long()\n",
    "        \n",
    "        #### GENERATOR FORWARD\n",
    "        optimizer_G.zero_grad()\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        rec = generator({\n",
    "            'content':real_content,\n",
    "            'style_label': autoflag_OHE, # 1-n_styles +1 ((nstyles))\n",
    "        })\n",
    "        err_Rec = criterion_Rec(rec,real_content)*autoencoder_constrain\n",
    "        err_Rec.backward()\n",
    "\n",
    "        #Gan Loss\n",
    "        genfake = generator({\n",
    "            'content':real_content,\n",
    "            'style_label': style_OHE,\n",
    "        })\n",
    "        \n",
    "        output = discriminator(genfake)\n",
    "        errG = criterion_GAN(output[0],fake_label)\n",
    "        errG.backward(retain_graph=True)\n",
    "\n",
    "        #https://github.com/pytorch/pytorch/issues/29\n",
    "        #Aux Class Loss\n",
    "        errG_AC = criterion_ACGAN(output[1].transpose(1,3),class_label)*lambda_A\n",
    "        errG_AC.backward(retain_graph=True)\n",
    "\n",
    "        err_TV = criterion_TV(genfake)\n",
    "        err_TV.backward()\n",
    "        \n",
    "        total_loss_G = err_Rec + errG + errG_AC + err_TV\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        #### DISCRIMINATOR UPDATE\n",
    "        optimizer_D.zero_grad()\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        #Real Loss\n",
    "        output = discriminator(real_style)\n",
    "\n",
    "        errD_real_class = criterion_ACGAN(output[1].transpose(1,3),class_label)\n",
    "        errD_real_class.backward(retain_graph=True)\n",
    "\n",
    "        errD_real = criterion_GAN(output[0],real_label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        #Fake Loss\n",
    "        fake = fake_buffer.push_and_pop(genfake)\n",
    "        out_real, out_class = discriminator(fake)\n",
    "        errD_fake = criterion_GAN(out_real,fake_label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = (errD_real+errD_fake)/2.0\n",
    "\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        #Progress report (port 8097)\n",
    "        #TODO add tv loss to tracker\n",
    "        logger.log({'loss_G': total_loss_G, 'loss_G_AE': err_Rec, 'loss_G_GAN': errG,\n",
    "                    'loss_G_AC': errG_AC, 'loss_D': errD, 'errD_fake':errD_fake,'tv_oss':err_TV,\n",
    "                   'errD_real':errD_real, 'errD_class': errD_real_class}, \n",
    "                    images={'content': real_content, 'style': real_style, 'transfer': genfake,'auto-reconstruction':rec})\n",
    "    \n",
    "    ##update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D.step()\n",
    "    \n",
    "    #Save model\n",
    "    torch.save(generator.state_dict(), 'output/netG.pth')\n",
    "    torch.save(discriminator.state_dict(), 'output/netD.pth')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
