{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install visdom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "import numpy as np\n",
    "# vis = visdom.Visdom()\n",
    "# vis.text('Hello, world!')\n",
    "# vis.image(np.ones((3, 10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from data import *\n",
    "from models import *\n",
    "from utils import *\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN OPTIONS FROM GATED GAN\n",
    "epoch = 0\n",
    "n_epochs = 200 #default = 200\n",
    "batchSize = 1\n",
    "dataroot = './photo2fourcollection'\n",
    "loadSize = 143\n",
    "fineSize = 128\n",
    "ngf = 64\n",
    "ndf = 64    \n",
    "in_nc = 3 \n",
    "out_nc = 3 \n",
    "niter = 100  \n",
    "niter_decay = 100 \n",
    "lr = 0.0002 \n",
    "beta1 = 0.5 \n",
    "#ntrain = math.huge \n",
    "flip = 1  \n",
    "display_id = 10 \n",
    "display_winsize = 128 \n",
    "display_freq = 25 \n",
    "gpu = 1 \n",
    "name = ''   \n",
    "which_direction = 'AtoB'\n",
    "phase = 'train'\n",
    "nThreads = 2\n",
    "save_epoch_freq = 1\n",
    "save_latest_freq = 5000 \n",
    "print_freq = 50\n",
    "save_display_feq = 2500\n",
    "continue_train = 0\n",
    "serial_batches = 0\n",
    "checkpoints_dir = './checkpoints'\n",
    "cudnn = 1\n",
    "which_model_netD = 'basic'\n",
    "which_model_netG = 'auto_gated_resnet_6blocks'\n",
    "norm = 'instance'\n",
    "n_layers_D = 3\n",
    "lambda_A = 10.0\n",
    "model = 'gated_gan'\n",
    "use_lsgan = True\n",
    "align_data = 0\n",
    "pool_size = 50\n",
    "resize_or_crop = 'resize_and_crop'\n",
    "autoencoder_constrain = 10 \n",
    "n_styles = 4\n",
    "test_data_path = ''\n",
    "decay_epoch=100\n",
    "cuda=False\n",
    "tv_strength=1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ImageDataset('./photo2fourcollection'), \n",
    "                        batch_size=1, shuffle=True, num_workers=4)\n",
    "batch = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['style_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(in_nc, out_nc, n_styles, ngf)\n",
    "discriminator= Discriminator(in_nc,n_styles, ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.load_state_dict(torch.load('./output/netG.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Losses Init\n",
    "use_lsgan=True\n",
    "if use_lsgan:\n",
    "    criterion_GAN = nn.MSELoss()\n",
    "else: \n",
    "    criterion_GAN = nn.BCELoss()\n",
    "    \n",
    "    \n",
    "criterion_ACGAN = nn.CrossEntropyLoss(weight=None)\n",
    "criterion_Rec = nn.L1Loss()\n",
    "#criterion_Enc = nn.MSELoss()\n",
    "criterion_TV = TVLoss(TVLoss_weight=tv_strength)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers & LR schedulers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),\n",
    "                                lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), \n",
    "                               lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch,decay_epoch).step)\n",
    "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(n_epochs,epoch, decay_epoch).step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (fldiscriminator): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       "  (aux_clf): Conv2d(512, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set vars for training\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "input_A = Tensor(batchSize, in_nc, fineSize, fineSize)\n",
    "input_B = Tensor(batchSize, out_nc, fineSize, fineSize)\n",
    "target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "# print(Tensor(batch['style']))\n",
    "D_A_size = discriminator(input_A.copy_(batch['style']))[0].size()  \n",
    "D_AC_size = discriminator(input_B.copy_(batch['style']))[1].size()\n",
    "# print(D_AC_size)\n",
    "\n",
    "class_label_B = Tensor(D_AC_size[0],D_AC_size[1],D_AC_size[2]).long()\n",
    "# print(class_label_B.shape)\n",
    "\n",
    "autoflag_OHE = Tensor(1,n_styles+1).fill_(0).long()\n",
    "autoflag_OHE[0][-1] = 1\n",
    "\n",
    "fake_label = Tensor(D_A_size).fill_(0.0)\n",
    "real_label = Tensor(D_A_size).fill_(0.99) \n",
    "\n",
    "rec_A_AE = Tensor(batchSize,in_nc,fineSize,fineSize)\n",
    "\n",
    "fake_buffer = ReplayBuffer()\n",
    "\n",
    "##INIT THOSE WEIGHTS INIT\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(n_epochs, len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check out our training tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #source image\n",
    "# real_content = Variable(input_A.copy_(batch['content']))\n",
    "# #target style\n",
    "# real_style = Variable(input_B.copy_(batch['style']))\n",
    "# #simple label of style index\n",
    "# style_label = batch['style_label']\n",
    "# #one hot encoded style label\n",
    "# style_OHE = F.one_hot(style_label,n_styles).long()\n",
    "# #\n",
    "# class_label = class_label_B.copy_(label2tensor(style_label,class_label_B)).long()\n",
    "\n",
    "# #\n",
    "# #rec_AE = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 [0050/6287] -- Generator Loss: 13.2537 | Reconstruction Loss: 4.1291 | loss_G_GAN: 0.9299 | loss_G_AC: 12.3236 | Discriminator GAN Loss: 0.8111 | tv_loss: 0.0001 | errD_class: 18.1061 -- ETA: 23 days, 5:42:38.6432502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/colemiller1/anaconda3/envs/learn-env/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cf894dc77f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0merrG_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_gan\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merr_class\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merr_TV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0merrG_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TRAIN LOOP\n",
    "for epoch in range(epoch,n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_content = Variable(input_A.copy_(batch['content']))\n",
    "        real_style = Variable(input_B.copy_(batch['style']))\n",
    "        style_label = batch['style_label']\n",
    "        style_OHE = F.one_hot(style_label,n_styles).long()\n",
    "        \n",
    "        class_label = class_label_B.copy_(label2tensor(style_label,class_label_B)).long()\n",
    "        \n",
    "        #### Update Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        #err_Rec.backward()\n",
    "\n",
    "        #Fake Loss\n",
    "        genfake = generator({\n",
    "            'content':real_content,\n",
    "            'style_label': style_OHE,\n",
    "        })\n",
    "        \n",
    "        fake = fake_buffer.push_and_pop(genfake)\n",
    "        out_gan, out_class = discriminator(fake)\n",
    "        errD_fake = criterion_GAN(out_gan, fake_label)\n",
    "        #Discriminator Classifier is not trained on fake images\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "        #Real Loss\n",
    "        optimizer_D.zero_grad()\n",
    "        out_gan, out_class = discriminator(real_style)\n",
    "\n",
    "        errD_real_class = criterion_ACGAN(out_class.transpose(1,3),class_label)*lambda_A\n",
    "        #errD_real_class.backward(retain_graph=True)\n",
    "\n",
    "        errD_real = criterion_GAN(out_gan, real_label)\n",
    "        #errD_real.backward()\n",
    "        \n",
    "        errD_real_total = errD_real + errD_real_class\n",
    "        errD_real_total.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "        errD = (errD_real+errD_fake)/2.0\n",
    "        \n",
    "                \n",
    "        #### Generator Update\n",
    "        optimizer_G.zero_grad()\n",
    "        out_gan, out_class = discriminator(genfake)\n",
    "        \n",
    "        err_gan = criterion_GAN(out_gan, real_label)\n",
    "        err_class = criterion_ACGAN(out_class.transpose(1,3), class_label)*lambda_A\n",
    "        \n",
    "        err_TV = criterion_TV(genfake)\n",
    "        \n",
    "        errG_tot = err_gan + err_class + err_TV \n",
    "        \n",
    "        errG_tot.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        identity = generator({\n",
    "            'content': real_content,\n",
    "            'style_label': autoflag_OHE,\n",
    "        })\n",
    "        err_ae = criterion_Rec(identity,real_content)*autoencoder_constrain\n",
    "        err_ae.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \n",
    "        #Progress report (port 8097)\n",
    "        logger.log({'Generator Loss': errG_tot,\n",
    "                    'Reconstruction Loss': err_ae,\n",
    "                    'loss_G_GAN': err_gan,\n",
    "                    'loss_G_AC': err_class,\n",
    "                    'Discriminator GAN Loss': errD,\n",
    "                    'tv_loss':err_TV,\n",
    "                    'errD_class': errD_real_class}, \n",
    "                    images={'content': real_content,\n",
    "                            'style': real_style,\n",
    "                            'transfer': genfake,\n",
    "                            'auto-reconstruction':identity})\n",
    "    \n",
    "    ##update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D.step()\n",
    "    \n",
    "    #Save model\n",
    "    torch.save(generator.state_dict(), 'output/netG.pth')\n",
    "    torch.save(discriminator.state_dict(), 'output/netD.pth')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
